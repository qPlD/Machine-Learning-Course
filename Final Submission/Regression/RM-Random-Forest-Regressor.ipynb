{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "#model import \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#splitting and scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#parameter tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#evaluation\n",
    "from sklearn import linear_model, metrics\n",
    "from sklearn.metrics import (mean_squared_error, r2_score, mean_absolute_error, \n",
    "mean_squared_log_error, explained_variance_score, max_error)\n",
    "from sklearn.model_selection import LeaveOneOut, cross_val_score, cross_val_predict\n",
    "\n",
    "import warnings\n",
    "# We silence warnings concerning future version updates\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and testing data\n",
    "X_train = np.loadtxt(\"X_train.csv\", delimiter=',', skiprows=1)\n",
    "X_test = np.loadtxt(\"X_test.csv\", delimiter=',', skiprows=1)\n",
    "y_train = np.loadtxt(\"y_train.csv\", delimiter=',', skiprows=1)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveFile(y_pred,name):\n",
    "    test_header = \"Id,PRP\"\n",
    "    n_points = X_test.shape[0]\n",
    "    y_pred_pp = np.ones((n_points, 2))\n",
    "    y_pred_pp[:, 0] = range(n_points)\n",
    "    y_pred_pp[:, 1] = y_pred\n",
    "    np.savetxt(name, y_pred_pp, fmt='%d,%f', delimiter=\",\",\n",
    "               header=test_header, comments=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the dataset for training\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X_train, y_train, test_size=0.3, random_state=42)\n",
    "\n",
    "#scaling split training dataset\n",
    "scaler = StandardScaler()\n",
    "X_train1_scaled = scaler.fit_transform(X_train1)\n",
    "X_test1_scaled = scaler.fit_transform(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining basic untuned random forest regression model\n",
    "\n",
    "def basicrfr(X_train1, X_test1, y_train1, y_test1):\n",
    "    rfr = RandomForestRegressor(random_state = 0)\n",
    "    rfr.fit(X_train1, y_train1)\n",
    "    y_pred = rfr.predict(X_test1)\n",
    "    \n",
    "    print(\"R2 score: \" + str(rfr.score(X_train1, y_train1)))\n",
    "    print(\"Explained variance: \" + str(explained_variance_score(y_test1, y_pred)))\n",
    "    print(\"Max error: \" + str(max_error(y_test1, y_pred)))\n",
    "    print(\"Mean absolute error: \" + str(mean_absolute_error(y_test1, y_pred)))\n",
    "    print(\"Root mean squared error: \" + str(math.sqrt(mean_squared_error(y_test1, y_pred))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.9616061630082258\n",
      "Explained variance: 0.8979307222226864\n",
      "Max error: 112.19999999999999\n",
      "Mean absolute error: 22.09493464052288\n",
      "Root mean squared error: 35.677440209798505\n"
     ]
    }
   ],
   "source": [
    "# using standard training data\n",
    "basicrfr(X_train1, X_test1, y_train1, y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.960288631845655\n",
      "Explained variance: 0.7935244048163663\n",
      "Max error: 192.3\n",
      "Mean absolute error: 31.881437908496736\n",
      "Root mean squared error: 50.97707305585569\n"
     ]
    }
   ],
   "source": [
    "# using scaled training data\n",
    "basicrfr(X_train1_scaled, X_test1_scaled, y_train1, y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters currently in use:\n",
      "\n",
      "{'bootstrap': True, 'criterion': 'mse', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 'warn', 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "# Further Tuning with Grid Search\n",
    "rfr = RandomForestRegressor()\n",
    "# Look at parameters used by our regression\n",
    "print('Parameters currently in use:\\n')\n",
    "print(rfr.get_params())\n",
    "\n",
    "\n",
    "#Creating the parameter grid\n",
    "\n",
    "param_grid = [\n",
    "   {'max_depth': [None, 3, 5, 7],\n",
    "    'oob_score' : [True, False],\n",
    "    'min_samples_leaf':[1, 2], \n",
    "    'min_samples_split': [2, 3, 4],\n",
    "    'n_estimators': [100, 500, 1000, 2500, 5000],\n",
    "    'warm_start': [True, False]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 480 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   50.8s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed:  9.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed: 13.1min\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed: 17.1min\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed: 21.9min\n",
      "[Parallel(n_jobs=-1)]: Done 4800 out of 4800 | elapsed: 26.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5,\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 4,\n",
       " 'n_estimators': 100,\n",
       " 'oob_score': True,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit the model with the parameter\n",
    "rfr = GridSearchCV(RandomForestRegressor(), param_grid = param_grid, cv = 10, verbose=True, n_jobs=-1)\n",
    "# Fit the random search model\n",
    "best_reg= rfr.fit(X_train1_scaled, y_train1)\n",
    "\n",
    "\n",
    "best_reg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tunedrfr(X_train1, X_test1, y_train1, y_test1):\n",
    "    rfr = RandomForestRegressor(max_depth = 5, min_samples_leaf = 2, min_samples_split = 4, n_estimators = 100, oob_score = True, warm_start = False, random_state = 0)\n",
    "    rfr.fit(X_train1, y_train1)\n",
    "    y_pred = rfr.predict(X_test1)\n",
    "    \n",
    "    print(\"R2 score: \" + str(rfr.score(X_train1, y_train1)))\n",
    "    print(\"Explained variance: \" + str(explained_variance_score(y_test1, y_pred)))\n",
    "    print(\"Max error: \" + str(max_error(y_test1, y_pred)))\n",
    "    print(\"Mean absolute error: \" + str(mean_absolute_error(y_test1, y_pred)))\n",
    "    print(\"Root mean squared error: \" + str(math.sqrt(mean_squared_error(y_test1, y_pred))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.9276144927762131\n",
      "Explained variance: 0.8671487422024539\n",
      "Max error: 126.69923370927319\n",
      "Mean absolute error: 29.62469746651357\n",
      "Root mean squared error: 42.38705061801293\n"
     ]
    }
   ],
   "source": [
    "tunedrfr(X_train1_scaled, X_test1_scaled, y_train1, y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run our final prediction\n",
    "rfr_tuned = RandomForestRegressor(max_depth = 5, min_samples_leaf = 2, min_samples_split = 4, n_estimators = 100, oob_score = True, warm_start = False, random_state = 0)\n",
    "rfr_tuned.fit(X_train_scaled, y_train)\n",
    "y_pred = rfr_tuned.predict(X_test_scaled)\n",
    "saveFile(y_pred, \"randomForest_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
